{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b96791d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "629a5cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== Decision Tree Classifier Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9960869883971739\n",
      "\n",
      "Model Accuracy:\n",
      " 1.0\n",
      "\n",
      "Confusion matrix:\n",
      " [[8245    0]\n",
      " [   0 9389]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       1.00      1.00      1.00      8245\n",
      "      normal       1.00      1.00      1.00      9389\n",
      "\n",
      "    accuracy                           1.00     17634\n",
      "   macro avg       1.00      1.00      1.00     17634\n",
      "weighted avg       1.00      1.00      1.00     17634\n",
      "\n",
      "\n",
      "\n",
      "============================== SVM Classifier Model Evaluation ==============================\n",
      "\n",
      "Cross Validation Mean Score:\n",
      " 0.9621754109093059\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9628558466598617\n",
      "\n",
      "Confusion matrix:\n",
      " [[7703  542]\n",
      " [ 113 9276]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     anomaly       0.99      0.93      0.96      8245\n",
      "      normal       0.94      0.99      0.97      9389\n",
      "\n",
      "    accuracy                           0.96     17634\n",
      "   macro avg       0.97      0.96      0.96     17634\n",
      "weighted avg       0.96      0.96      0.96     17634\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#==========our plot and panda settings because the dataset is large===================#\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set(style=\"darkgrid\")\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "#===================Loading and understanding the dataset better=============================#\n",
    "train = pd.read_csv(r'C:\\Users\\hp\\Desktop\\Train_data.csv')\n",
    "test = pd.read_csv(r'C:\\Users\\hp\\Desktop\\Test_data.csv')\n",
    "#print(test.head(5))\n",
    "#print(train.head(5))\n",
    "#train.describe()\n",
    "#test.describe()\n",
    "#print(\"Training data has {} rows & {} columns\".format(train.shape[0],train.shape[1]))\n",
    "#print(\"Test data has {} rows & {} columns\".format(test.shape[0],test.shape[1]))\n",
    "#print(train['num_outbound_cmds'].value_counts())\n",
    "#print(test['num_outbound_cmds'].value_counts())\n",
    "train.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "test.drop(['num_outbound_cmds'], axis=1, inplace=True)\n",
    "\n",
    "#=====scaling the numerical attribute, scaling is used to bring data points far from each other closer#\n",
    "#To do this i'm extracting the numerical attributes and making the mean and variance 0#\n",
    "scaler = StandardScaler()\n",
    "cols = train.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = scaler.fit_transform(train.select_dtypes(include=['float64','int64']))\n",
    "sc_test = scaler.fit_transform(test.select_dtypes(include=['float64','int64']))\n",
    "# Returning it to the data frame\n",
    "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
    "sc_testdf = pd.DataFrame(sc_test, columns = cols)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# extract categorical attributes from both training and test sets \n",
    "cattrain = train.select_dtypes(include=['object']).copy()\n",
    "cattest = test.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# encode the categorical attributes\n",
    "traincat = cattrain.apply(encoder.fit_transform)\n",
    "testcat = cattest.apply(encoder.fit_transform)\n",
    "\n",
    "# separate target column from encoded data \n",
    "enctrain = traincat.drop(['class'], axis=1)\n",
    "cat_Ytrain = traincat[['class']].copy()\n",
    "\n",
    "train_x = pd.concat([sc_traindf,enctrain],axis=1)\n",
    "train_y = train['class']\n",
    "#print(train_x.shape)\n",
    "\n",
    "test_df = pd.concat([sc_testdf,testcat],axis=1)\n",
    "#print(test_df.shape)\n",
    "\n",
    "#===========For our feature selection, we'll be using a package known as ensemble===========#\n",
    "# we'll be using a Random forest classifier for it\n",
    "\n",
    "# fit random forest classifier on the training set\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(train_x, train_y);\n",
    "# extract important features\n",
    "score = np.round(rfc.feature_importances_,3)\n",
    "importances = pd.DataFrame({'feature':train_x.columns,'importance':score})\n",
    "importances = importances.sort_values('importance',ascending=False).set_index('feature')\n",
    "# plot importances\n",
    "plt.rcParams['figure.figsize'] = (11, 4)\n",
    "#importances.plot.bar();\n",
    "# The graph i just plotted ranks the most important features of the dataset by getting the scores of each\n",
    "   # feature and ranking them in a descending order(from highest to lowest)\n",
    "    #from the graph you can see that source_bytes is the most important feature of the dataset\n",
    "    \n",
    "# now we have to use the RFE(Recursive feature elimination) model to fit a model and remove the weakest\n",
    "  #features cos they will have little or no effect on the model\n",
    "    \n",
    "# create the RFE model and select 15 attributes\n",
    "rfe = RFE(rfc, n_features_to_select=15)\n",
    "rfe = rfe.fit(train_x, train_y)\n",
    "\n",
    "# summarize the selection of the attributes\n",
    "feature_map = [(i, v) for i, v in itertools.zip_longest(rfe.get_support(), train_x.columns)]\n",
    "selected_features = [v for i, v in feature_map if i==True]\n",
    "\n",
    "#selected_features\n",
    "\n",
    "# Basically the above block of code tells the RFE model to pick just the 15 most important features\n",
    "#These are the features we will use to train our model\n",
    "\n",
    "# now let me split my data into training and testing and also fit in my models\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(train_x,train_y,train_size=0.70, random_state=2)\n",
    "\n",
    "# Train Decision Tree Model\n",
    "DTC_Classifier = tree.DecisionTreeClassifier(criterion='entropy', random_state=0)\n",
    "DTC_Classifier.fit(X_train, Y_train)\n",
    "\n",
    "#Train SVM model\n",
    "SVM_Classifier = SVC(random_state=0)\n",
    "SVM_Classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Now i want to evaluate the models with popular performance metrics\n",
    "\n",
    "models = []\n",
    "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
    "models.append(('SVM Classifier', SVM_Classifier))\n",
    "\n",
    "# i am using 4 well known performance metrics to evaluate the performance of my model\n",
    "# score, accuracy, confusion matrix, classification\n",
    "for i, v in models:\n",
    "    scores = cross_val_score(v, X_train, Y_train, cv=10)\n",
    "    accuracy = metrics.accuracy_score(Y_train, v.predict(X_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(Y_train, v.predict(X_train))\n",
    "    classification = metrics.classification_report(Y_train, v.predict(X_train))\n",
    "    print()\n",
    "    print('============================== {} Model Evaluation =============================='.format(i))\n",
    "    print()\n",
    "    print (\"Cross Validation Mean Score:\" \"\\n\", scores.mean())\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()\n",
    "    # why the code is this bulky is because i want to achieve a better result when i train my models\n",
    "    # and in order to achieve that i have to entirely manipulate my data and remove unwanted features\n",
    "    # that will affect the accuracy of my model\n",
    "    # and as you can see decision tree algorithm has an average score of 100%\n",
    "    # and the confusion matrix tells us that the model didn't make even one wrong prediction\n",
    "    \n",
    "    \n",
    "    \n",
    "    # copyright PROTEK\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
